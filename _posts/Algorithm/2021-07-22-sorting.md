---
layout: post
navigation: True
title: sorting - 정렬 알고리즘
tags: [python]
class: post-template
subclass: "post tag-python"
author: parkjju
---

# 정렬 알고리즘

- 리스트(배열)의 값을 오름차순으로 재배치
- **목표 : 비교횟수 + 교환횟수를 최소화**

```python
A = [3,1,2,-5]
A.sort() # A = [-5,1,2,3]
A.sort(reverse=True) # A = [3,2,1,-5]
```

- 정렬 알고리즘의 성질

1. stable vs unstable - A = \[2,5,2,7\] , A.sort() == \[2,2,5,7\] (같은 숫자가 입력된 경우, **입력 순서에 따라 원소를 배치할 경우 stable하다**, 가능하면 stable한 정렬 알고리즘이 바람직하다)
2. in-place vs not in-place - 정렬 시 추가적으로 사용하는 메모리의 여부
   - in-place : 추가 메모리를 O(1)
   - not in-place : 추가 메모리를 O(n)시간에 사용, 입력의 크기만큼 메모리를 마련

## 기본 알고리즘 - 간단하지만 느린 알고리즘

- selection, bubble, insertion : (n-1)번의 round - 매 라운드마다 sorting순서에 맞는 위치로 원소를 보냄

1. selection : for each round, find maximum & swap max and last
   - 비교 : (n-1) + (n-2) + ... + 1 -> n(n-1)/2
   - 교환 : 전체 (n-1)번
2. bubble : for each round, 2값씩 비교 - 최대값을 가장 마지막으로 보낸다.
   - 비교 : (n-1) + (n-2) + ... + 1 -> n(n-1)/2
   - 교환 : 최악의 경우 n(n-1)/2
3. insertion : insert a value at correct position
   - 비교 : 1 + 2 + ... + (n-2) + (n-1) -> 최악의 경우
   - 교환 : 1 + 2 + ... + (n-2) + (n-1) -> 최악의 경우

- 기본 세 가지 알고리즘 최악의 경우 수행시간 O(n^2)
- is in-place? : 리스트 내에서 스왑 진행되므로 성립
- is stable? : Q&A

## Quick sort 알고리즘 : 실제로 가장 빠른 정렬 알고리즘

- QuickSelect 알고리즘으로 정렬한다. S,M,L순으로 정렬되었다고 가정할때 M은 이미 정렬되어 있는 상태인 것이다.
- QuickSelect와는 다르게 S,L 둘다 정렬을 진행해야한다.

```python
# pseudo
def quick_sort(A):
    if len(A)<=1: return A
    p = A[0]
    S, M, L = [], [], []
    for x in A:
        if p>x:
            S.append(x)
        elif p<x:
            L.append(x)
        else:
            M.append(x)
    return quick_sort(S) + M + quick_sort(L)
```

```python
# not in-place
import random
def quickSort(A, first, last):
    if first >= last: return
    left, right = first+1, last
    pivot = A[first]
    while left <= right:
        while left <= last and A[left] < pivot:
            left += 1
        while right > first and A[right] >= pivot:
            right -= 1
        if left <= right: # swap A[left] and A[right]
            A[left], A[right] = A[right], A[left]
            left += 1
            right -= 1
    # place pivot at the right place
    A[first], A[right] = A[right], A[first]
    quickSort(A, first, right-1)
    quickSort(A, right+1, last)

n = int(input("n = "))
random.seed()
A = [random.randint(1, 100) for x in range(n)]
print(A)
quickSort(A, 0, len(A)-1)
print(A)
```

- not in-place : S, M, L리스트를 복사하여 정렬을 진행하였음.
- stable : for x in A로 진행됨 -> 선형적으로 순회가 진행됨

<figure>
<img src="./assets/images/quicksortO.jpg" height="80%" width="80%"/>
<figcaption> quick sort 수행시간 </figcaption>
</figure>

- pivot설정이 극단적인 경우에만 O(n^2)시간이 필요하고 일반적인 경우에는 O(nlogn)시간으로 고려하면된다.

### in-place quick sort algorithm (새로운 리스트에 값을 복사하지 않도록 구현)

```python
A = [4,2,5,8,6,2,3,7,10]

def quick_sort(A,first,last):
    # A[first] ... A[last]를 quick sort.
    p = A[first]
    left = first+1
    right = last

    while left <= right: # S, M, L구하기
        while left <= last and A[left] < p:
            left += 1
        while A[right] > p:
            right -= 1
        if left <= right:
            A[left], A[right] = A[right], A[left]
            left += 1
            right -= 1
        A[first], A[right] = A[right], A[first]
    quick_sort(A, first, right-1)
    quick_sort(A, left, last)
```

```python
# in-place
import random
def quickSort2(A):
    if len(A) <= 1: return A
    pivot = A[0]
    S, M, L = [], [], []
    for x in A:
        if x < pivot: S.append(x)
        elif x > pivot: L.append(x)
        else: M.append(x)
    return quickSort2(S)+M+quickSort2(L)

random.seed()
n = int(input("n = "))
A = [random.randint(1, 10) for x in range(n)]
print(A)
A=quickSort2(A)
print(A)
```

<figure>
<img src="./assets/images/inplacesort.jpg" height="80%" width="80%"/>
<figcaption> inplace Quick Sort </figcaption>
</figure>

- in-place하지만, stable한지는 직접 판단하기

* 위 예제로 제시된 A리스트 기준으로 마지막 right과 pivot을 교체하는 과정에서 first+1에 위치했던 2값보다 right에 위치했던 2값이 더 앞으로 정렬된다. 따라서 not stable하다고 할 수 있다.

## Merge sorting Algorithm (병합 정렬 알고리즘)

- Quick sort -> T(n) = T(|S|) + T(|L|) + cn, cn번의 비교를 통해 S, L, M 을 구분
- |S|, |L|은 다양한 상황에 따라 달라질 수 있다.
- pivot설정에 힘을 주면 다양한 상황을 줄일 수 있다.

1. p = MOM(A, |A|/2)
2. |S| = |L| ~= n/2
3. quicksort(S) + p + quicksort(L), O(nlogn)

- MoM자체가 간단하지 않을 뿐더러 O(n) 수행시간의 cn 계수값 c가 너무 크다는 한계가 있다.

- 이에 따라 리스트를 **강제로 반씩 나누어** 정렬을 진행한다.

<figure>
<img src="./assets/images/mergeSort.jpg" height="80%" width="80%"/>
<figcaption> merge sort 예시 </figcaption>
</figure>

```python
# merge sort pseudo code
def merge_sort(A,first,last): # A[first] .. A[last] merge sort
    if first >= last: return
    merge_sort(A, first, (first+last)//2)
    merge_sort(A, (first+last)//2 + 1, last)
    merge_two_sorted_lists(A,first,last)

def merge_two_sorted_lists(A, first, last):
    m = (first+last)//2
    i,j = first, m+1
    B = []

    while i<=m and j <= last:
        if A[i]<=A[j]:
            B.append(A[i])
            i += 1
        else:
            B.append(A[j])
            j+=1
    for k in range(i, m+1): # 두 for문 중 정확하게 하나만 돌아가게 된다.
        B.append(A[k])
    for k in range(j, last+1):
        B.append)A[k])

    for i in range(first, last+1):
        A[i] = B[i-first]
```

1. i, j가 이동하면서 first부터 last까지 총 cn번 비교
2. B리스트 마련 후 이동 -> n번
3. swap도 n번

- T(n) = 2T(n/2) + cn = O(nlogn) , worst-best-average 모두 nlogn시간에 정렬이되며 현재까지의 정렬 알고리즘 중에 최적임.

## 정렬 알고리즘의 비교횟수에 대한 하한(lower bound)

- **비교 중심 알고리즘**
- selection, bubble, insertion -> O(n^2)
- quick, merge, heap -> O(nlogn)

- 입력으로 주어진 숫자에 대해서 if문을 통해 대소관계를 결정하는 데, 이러한 과정이 **트리 형태로 나타나게된다**
<figure>
<img src="./assets/images/decisionTree.jpg" height="80%" width="80%"/>
<figcaption> Decision Tree </figcaption>
</figure>

- 최종적으로 6개의 leaf가 나타남. -> 3! = 6
- 어떠한 정렬 알고리즘도 최소한 3번 비교를 진행해야한다. (decision tree의 높이 h=3)

### n개 값으로 확장

<figure>
<img src="./assets/images/decisipnTree2.jpg" height="80%" width="80%"/>
<figcaption> n개의 원소일 경우 decision tree </figcaption>
<img src="./assets/images/calH.jpg" height="80%" width="80%"/>
<figcaption> 높이 h계산 - heap을 전제로 </figcaption>
</figure>

- 최소 c\*nlogn만큼 비교를 진행해야하는데 merge와 heap은 평균 시간이 O(nlogn)시간이 걸리므로 최적이다.
- 비교하지 않고 정렬하는 알고리즘? - Radix알고리즘

## Tim 정렬 알고리즘

- Tim peters - python sort힘수로 사용
- insertion + merge

### insertion 알고리즘 분석

- 기존 insertion 알고리즘 -> 인덱스0부터 시작하여 정렬된 부분 리스트를 두고, 부분 리스트 다음 인덱스의 원소를 부분 리스트 최 우측 원소부터 왼쪽으로 차례로 비교하여 swap을 진행.

- 위의 비교를 선형적으로 진행하지 않고 binary-search를 통해 진행한다. : O(logn) -> 인덱스를 찾아주는 시간 + 비교대상 값 x가 들어갈 위치 이후로 한칸씩 옮겨주는 시간 -> O(n)
- round : O(n) X O(n) => O(n^2)

- 많은 숫자들에 대해 정렬이 되어있는 상태이면, insertion 알고리즘이 가장 효율적이다. O(n)비교, 0번의 이동

### merge 알고리즘 분석

- not in-place가 일반적
<figure>
<img src="./assets/images/mergeInplace.jpg" height="80%" width="80%"/>
<figcaption> 반만 in-place로 merge를 진행 </figcaption>
</figure>

- 꼭 반씩 쪼갤 필요는 없고, 가령 8개중 2-6으로 쪼갤 경우 더 작은 부분의 리스트를 카피하여 B에 저장한다.
- 하지만 반씩 나누지 않은 경우 더 큰 개수의 부분 리스트 비교 및 merge진행시 앞으로 더 비교를 진행해야할 더 큰 부분리스트 원소가 사라지게 되는 문제가 발생

<figure>
<img src="./assets/images/timMerge.jpg" height="80%" width="80%"/>
<figcaption> 더 적은 메모리를 사용하여 copy 진행하기 </figcaption>
</figure>

- Tim sort에서는 merge알고리즘의 메모리의 효율성을 최대한 개선한다.

### Tim sort - run insertion sort

<figure>
<img src="./assets/images/run.jpg" height="80%" width="80%"/>
<figcaption> tim sort </figcaption>
</figure>

- 리스트를 run으로 쪼개고 각 run을 insertion으로 오름차순 정렬한뒤 최종 merge를 진행한다.

### Tim sort - run merge sort

- 스택 자료구조를 통해 run merge sort의 순서를 정한다.
<figure>
<img src="./assets/images/timsort2.jpg" height="80%" width="80%"/>
<figcaption> stack을 이용한 run merge sort </figcaption>
</figure>

- 최종적으로 스택에 남게되는 run의 개수가 O(logn)에 비례함.
- 스택의 사이즈 또한 스택에 남게되는 run의 사이즈와 동일하기 때문에 O(logn)에 비례하게 사이즈가 정해짐
- 스택에 남을 O(logn)개의 run들을 top부터 계속 merge하여 내려간다.

- merge에 필요한 시간 -> O(nlogn),
- Tim sort : worst case O(nlogn), not in-place, stable
- 부분적으로 다수 정렬되어있는 리스트가 입력으로 들어오면 O(n)시간에도 sorting 가능
